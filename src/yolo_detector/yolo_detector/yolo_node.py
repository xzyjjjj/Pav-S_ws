# TO FUCKING DO:
# 1) ä¸è¦å†ç»§ç»­å‘å¸ƒæ·±åº¦ä¿¡æ¯


#!/usr/bin/env python3
# coding=utf-8
from yolo_detector.detector_module import *
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from vision_msgs.msg import Detection2DArray, Detection2D, BoundingBox2D, ObjectHypothesisWithPose
from std_msgs.msg import Header

import cv2 
import numpy as np
from cv_bridge import CvBridge, CvBridgeError
import PIL.Image as PILImage

#* å°è£…rosäº¤äº’ï¼Œè®¢é˜…å›¾åƒã€å‘å¸ƒæ£€æµ‹ç»“æœ
class RosYOLODetector(Node):
    def __init__(self):
        super().__init__('ros_yolo_detector')  # è°ƒç”¨çˆ¶ç±»æ„é€ å™¨ï¼Œä¼ å…¥èŠ‚ç‚¹å

        # 1. å£°æ˜å‚æ•°
        self.declare_parameter('weights_path', 'yolov5l.pt')
        self.declare_parameter('config_path', './data/coco.yaml')
        self.declare_parameter('image_topic', '/camera/color/image_raw')
        self.declare_parameter('depth_topic', '/camera/depth/image_raw')
        self.declare_parameter('target_lab_name', '') # ? è®¾ç½®ä¸€ä¸ªç›®æ ‡æ£€æµ‹ç±»åˆ«ã€‚ç”¨äºæ£€æµ‹å¯¹å•ä¸ªç±»åˆ«ç‰©ä½“çš„è¯†åˆ«æ•ˆæœã€‚
        self.declare_parameter('enable_vis', False)
        self.declare_parameter('skip_frames', 3)
        
        # --- æ–°å¢å‚æ•°ï¼šç”¨äºé¢„å¤„ç† ---
        self.declare_parameter('enable_preprocessing', False) # æ˜¯å¦å¯ç”¨é¢„å¤„ç†
        self.declare_parameter('glare_threshold', 245)      # é«˜å…‰æ£€æµ‹çš„äº®åº¦é˜ˆå€¼ (0-255)
        self.declare_parameter('clahe_clip_limit', 2.0)     # CLAHE å¯¹æ¯”åº¦é™åˆ¶
        self.declare_parameter('clahe_tile_grid_size', 8)   # CLAHE ç½‘æ ¼å¤§å°

        # 2. è·å–å‚æ•°å€¼
        weights_path = self.get_parameter('weights_path').get_parameter_value().string_value
        config_path = self.get_parameter('config_path').get_parameter_value().string_value
        image_topic = self.get_parameter('image_topic').get_parameter_value().string_value
        depth_topic = self.get_parameter('depth_topic').get_parameter_value().string_value
        target_lab_name = self.get_parameter('target_lab_name').get_parameter_value().string_value
        enable_vis = self.get_parameter('enable_vis').get_parameter_value().bool_value
        skip_frames = self.get_parameter('skip_frames').get_parameter_value().integer_value
        
        # --- è·å–é¢„å¤„ç†å‚æ•° ---
        enable_preprocessing = self.get_parameter('enable_preprocessing').get_parameter_value().bool_value
        glare_threshold = self.get_parameter('glare_threshold').get_parameter_value().integer_value
        clahe_clip_limit = self.get_parameter('clahe_clip_limit').get_parameter_value().double_value
        clahe_tile_size = (self.get_parameter('clahe_tile_grid_size').get_parameter_value().integer_value, 
                                self.get_parameter('clahe_tile_grid_size').get_parameter_value().integer_value)
        
        self.enable_preprocessing = enable_preprocessing
        self.glare_threshold = glare_threshold
        self.clahe_clip_limit = clahe_clip_limit
        self.clahe_tile_size = clahe_tile_size
        if self.enable_preprocessing:
            self.get_logger().info(f"Use preprocess!--")

        # --- åˆå§‹åŒ– CLAHE å¯¹è±¡ ---
        self.clahe = cv2.createCLAHE(clipLimit=self.clahe_clip_limit, tileGridSize=self.clahe_tile_size)


        # 3. ä½¿ç”¨è·å–åˆ°çš„å˜é‡æ¥åˆå§‹åŒ–æ¨¡å‹å¯¹è±¡
        self.model = DetectorYolov5(cfgfile=config_path, weightfile=weights_path)
        if self.model.device == "cuda": 
            # æ‰“å°æ‰€ä½¿ç”¨çš„ GPU ä¿¡æ¯
            gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else "Unknown GPU"
            self.get_logger().info(f"âœ… Detector initialized using: CUDA ({gpu_name})")

        else:
            self.get_logger().warn("âŒ Detector initialized using: CPU (CUDA not available)")
            self.get_logger().info("Using CPU instead for detection.") # å°†æç¤ºä¿¡æ¯æ”¹ä¸º info çº§åˆ«
            
        
        # ? ï¼ˆæµ‹è¯•ç”¨ï¼‰è®¾ç½®ä¸€ä¸ªç›®æ ‡æ£€æµ‹ç±»åˆ«ã€‚ç”¨äºæ£€æµ‹å¯¹å•ä¸ªç±»åˆ«ç‰©ä½“çš„è¯†åˆ«æ•ˆæœã€‚
        self.target_lab_name = target_lab_name

        self.bridge = CvBridge()

        # è®¢é˜…å›¾åƒè¯é¢˜
        self.image_sub = self.create_subscription(
            Image, image_topic, self.image_callback, 10)
        
        # è®¢é˜…æ·±åº¦å›¾åƒè¯é¢˜
        self.depth_sub = self.create_subscription(
            Image, depth_topic, self.depth_callback, 10)

        # å‘å¸ƒæ£€æµ‹æ¡†ï¼ˆåªä¿ç•™ vehicleï¼‰
        self.detection_pub = self.create_publisher(Detection2DArray, "/yolo_detections", 10)
        
        # å‘å¸ƒRGBå›¾åƒ
        self.rgb_pub = self.create_publisher(Image, "/rgb_img", 10)
        
        # å‘å¸ƒæ·±åº¦å›¾åƒ
        self.depth_pub = self.create_publisher(Image, "/depth_img", 10)

        self.enable_vis = enable_vis

        # --- (å¯é€‰) å‘å¸ƒé¢„å¤„ç†åçš„å›¾åƒï¼Œç”¨äºè°ƒè¯• ---
        if self.enable_vis:
            self.get_logger().info(f"âœ… preprocessed image publisher init.")
            self.preprocessed_pub = self.create_publisher(Image, "/preprocessed_image", 10)


        # æ§åˆ¶å¸§ç‡
        self.frame_count = 0  # åˆå§‹åŒ–æ¥æ”¶çš„å›¾ç‰‡æ€»æ•°
        self.skip_frames = skip_frames  # æ¯ç¬¬3å¸§å¤„ç†ä¸€æ¬¡
        
        # å­˜å‚¨æœ€æ–°çš„æ·±åº¦å›¾åƒ
        self.latest_depth_image = None
        self.latest_depth_header = None

    def depth_callback(self, depth_msg):
        """æ·±åº¦å›¾åƒå›è°ƒå‡½æ•°ï¼Œå­˜å‚¨æœ€æ–°çš„æ·±åº¦å›¾åƒ"""
        self.latest_depth_image = depth_msg

    def image_callback(self, ros_img):
        self.frame_count += 1
        # è·³å¸§å¤„ç†
        if self.frame_count % (self.skip_frames + 1) != 0:
            return

        self.get_logger().info(f"\n--- âš¡ï¸ Processing Frame: {self.frame_count} (Seq: {ros_img.header.stamp.sec}.{ros_img.header.stamp.nanosec}) ---")
        try: # å°† ROS å›¾åƒæ¶ˆæ¯è½¬æ¢ä¸º OpenCV çš„ BGR8 æ ¼å¼å›¾åƒ
            cv_image = self.bridge.imgmsg_to_cv2(ros_img, "bgr8")
        except CvBridgeError as e:
            self.get_logger().error(f"CvBridge Error: {e}")
            return

        # # ================================================================
        # # --- å¼€å§‹ï¼šæ–°å¢çš„å›¾åƒé¢„å¤„ç†é€»è¾‘ ---
        # # ================================================================

        # if self.enable_preprocessing:
        #     # æ­¥éª¤ 1: é«˜å…‰å»é™¤ (Inpainting)
        #     # å°†å›¾åƒè½¬ä¸ºç°åº¦å›¾ï¼Œç”¨äºå¯»æ‰¾é«˜å…‰åŒºåŸŸ
        #     gray_img = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            
        #     # åˆ›å»ºé«˜å…‰åŒºåŸŸçš„æ©ç  (Mask)
        #     # self.glare_threshold æ˜¯ä¸€ä¸ªå¯è°ƒå‚æ•°ï¼Œä¾‹å¦‚ 245
        #     _, glare_mask = cv2.threshold(gray_img, self.glare_threshold, 255, cv2.THRESH_BINARY)
            
        #     # (å¯é€‰) å¯¹æ©ç è¿›è¡Œè†¨èƒ€ï¼Œç¡®ä¿è¦†ç›–é«˜å…‰è¾¹ç¼˜
        #     kernel = np.ones((2,2), np.uint8)
        #     glare_mask_dilated = cv2.dilate(glare_mask, kernel, iterations=1)
            
        #     # ä½¿ç”¨æ©ç å¯¹åŸå§‹ BGR å›¾åƒè¿›è¡Œä¿®å¤
        #     # cv2.INPAINT_NS (Navier-Stokes) é€Ÿåº¦è¾ƒå¿«ï¼Œé€‚åˆæ­¤ç±»ä¿®å¤
        #     inpainted_image = cv2.inpaint(cv_image, glare_mask_dilated, 3, cv2.INPAINT_NS)

        #     # æ­¥éª¤ 2: CLAHE (è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–)
        #     # æœ€å¥½åœ¨ LAB è‰²å½©ç©ºé—´çš„ L (äº®åº¦) é€šé“ä¸Šåº”ç”¨ CLAHEï¼Œä»¥é¿å…é¢œè‰²å¤±çœŸ
        #     lab_image = cv2.cvtColor(inpainted_image, cv2.COLOR_BGR2LAB)
        #     l_channel, a_channel, b_channel = cv2.split(lab_image)

        #     # åº”ç”¨ CLAHE
        #     clahe_l_channel = self.clahe.apply(l_channel)

        #     # åˆå¹¶å¤„ç†åçš„é€šé“
        #     merged_lab_image = cv2.merge([clahe_l_channel, a_channel, b_channel])

        #     # å°†å›¾åƒä» LAB è½¬å› BGR
        #     preprocessed_bgr_image = cv2.cvtColor(merged_lab_image, cv2.COLOR_LAB2BGR)
            
        #     # --- (å¯é€‰) å‘å¸ƒé¢„å¤„ç†åçš„å›¾åƒï¼Œç”¨äºè°ƒè¯• ---
        #     if self.enable_vis:
        #         try:
        #             preprocessed_msg = self.bridge.cv2_to_imgmsg(preprocessed_bgr_image, "bgr8")
        #             preprocessed_msg.header = ros_img.header
        #             self.preprocessed_pub.publish(preprocessed_msg)
        #         except CvBridgeError as e:
        #             self.get_logger().warn(f"Failed to publish preprocessed image: {e}")

        # else:
        #     # å¦‚æœä¸å¯ç”¨é¢„å¤„ç†ï¼Œåˆ™ç›´æ¥ä½¿ç”¨åŸå§‹å›¾åƒ
        #     preprocessed_bgr_image = cv_image
            
        # # ================================================================
        # # --- ç»“æŸï¼šæ–°å¢çš„å›¾åƒé¢„å¤„ç†é€»è¾‘ ---
        # # ================================================================


        # å°† BGR å›¾åƒè½¬ä¸º RGB å›¾åƒï¼Œå› ä¸º YOLOv5 å’Œ PIL åº“é€šå¸¸ä½¿ç”¨ RGB æ ¼å¼
        # æ³¨æ„ï¼šæˆ‘ä»¬ä½¿ç”¨ preprocessed_bgr_image è€Œä¸æ˜¯ cv_image
        # image = cv2.cvtColor(preprocessed_bgr_image, cv2.COLOR_BGR2RGB)
        image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB) #*switch

        image_pil = PILImage.fromarray(image) # å°† NumPy æ•°ç»„æ ¼å¼çš„å›¾åƒè½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡ï¼Œä»¥ä¾› DetectorYolov5 ç±»ä½¿ç”¨ã€‚
        
        #* è°ƒç”¨æ¨¡å‹è¿›è¡Œæ£€æµ‹
        result_image, bbox = self.model.detect(image_pil)
        bbox = bbox.cpu().detach().numpy()

        # å‘å¸ƒ RGB å›¾åƒ
        self.rgb_pub.publish(ros_img)
        
        # å‘å¸ƒæ·±åº¦å›¾åƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.latest_depth_image is not None:
            self.depth_pub.publish(self.latest_depth_image)

        # å‘å¸ƒ Detection2DArray æ¶ˆæ¯
        msg_array = Detection2DArray()
        msg_array.header = ros_img.header # å°†è¾“å…¥å›¾åƒçš„ headerï¼ˆåŒ…å«æ—¶é—´æˆ³å’Œåæ ‡ç³»ä¿¡æ¯ï¼‰èµ‹ç»™è¾“å‡ºæ¶ˆæ¯

        # # æ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡æ—¶ï¼Œå¡«å……ä¸€ä¸ªæ— æ•ˆçš„ç›®æ ‡ä¿¡æ¯åˆ°æ•°ç»„ä¸­
        # if len(bbox) == 0:
        # Â  Â  detection = Detection2D()
        # Â  Â  detection.bbox.center.position.x = 99999.0 # TODOï¼šè¡¨ç¤ºæœªæ£€æµ‹åˆ°ç›®æ ‡
        # Â  Â  detection.bbox.center.position.y = 99999.0
        # Â  Â  detection.bbox.size_x = 99999.0
        # Â  Â  detection.bbox.size_y = 99999.0

        # Â  Â  hypothesis = ObjectHypothesisWithPose()
        # Â  Â  hypothesis.hypothesis.class_id = "None" Â # vehicle ç±»åˆ«ID
        # Â  Â  hypothesis.hypothesis.score = 1.0
        # Â  Â  detection.results.append(hypothesis)
        # Â  Â  msg_array.detections.append(detection)

        top_label = bbox[:, 5]  # ä» bbox æ•°ç»„ä¸­æå–æ‰€æœ‰æ£€æµ‹æ¡†çš„ç±»åˆ« ID
        top_conf = bbox[:, 4]   # æå–ç½®ä¿¡åº¦ä¿¡æ¯
        top_boxes = bbox[:, :4] # æå– bbox ä½ç½®ä¿¡æ¯

        if(self.target_lab_name != ''):
            if self.target_lab_name not in self.model.yaml["names"].values():
                self.get_logger().warn(f"{self.target_lab_name} ç±»åˆ«ä¸åœ¨ class_names ä¸­ï¼")
                return
            # å°†ç›®æ ‡åç§°è½¬æ¢ä¸ºç±»åˆ« IDã€‚
            target_class_id = self.model.name2id(self.target_lab_name)
            # åˆ›å»ºä¸€ä¸ªå¸ƒå°”æ©ç ï¼Œç”¨äºç­›é€‰å‡ºæ‰€æœ‰ç±»åˆ«ä¸º self.target_lab_name çš„æ£€æµ‹ç»“æœã€‚
            target_class_mask = (top_label == target_class_id)

            if not np.any(target_class_mask):
                self.get_logger().info(f"--- ğŸš« Result: No {self.target_lab_name} detected ---")

            top_label = top_label[target_class_mask]
            top_conf = top_conf[target_class_mask]
            top_boxes = top_boxes[target_class_mask]

        # ç”¨äºæ—¥å¿—è¾“å‡ºçš„åˆ—è¡¨
        detected_classes = []
        # å¡«å……å¹¶å‘å¸ƒæ¶ˆæ¯
        for i in range(len(top_boxes)):
            box = top_boxes[i]
            conf = top_conf[i]      
            cls_id = top_label[i]   

            detection = Detection2D()
            class_name = self.model.id2name(cls_id)
            detected_classes.append(f"{class_name} ({conf:.2f})") # æ·»åŠ åˆ°æ—¥å¿—åˆ—è¡¨

            # å¡«å……bbox
            detection.bbox.center.position.x = float(box[0])
            detection.bbox.center.position.y = float(box[1])
            detection.bbox.size_x = float(box[2])
            detection.bbox.size_y = float(box[3])
            
            # å¡«å……ç±»åˆ«å’Œç½®ä¿¡åº¦
            hypothesis = ObjectHypothesisWithPose()
            hypothesis.hypothesis.class_id = class_name
            hypothesis.hypothesis.score = float(conf)
            detection.results.append(hypothesis)
            
            msg_array.detections.append(detection)

        self.detection_pub.publish(msg_array)
        # 2. è¾“å‡ºæ£€æµ‹ç»“æœ (æœ‰ç›®æ ‡æ£€æµ‹)
        if len(detected_classes) > 0:
            self.get_logger().info(f"--- âœ… Result: Detected {len(detected_classes)} items ---")
            for item in detected_classes:
                self.get_logger().info(f"   -> {item}")


        # å¯è§†åŒ–æ£€æµ‹ç»“æœï¼ˆå¦‚æœå¯ç”¨ï¼‰
        # æ³¨æ„ï¼šresult_image æ˜¯åŸºäº PIL å›¾åƒï¼ˆé¢„å¤„ç†åï¼‰ç»˜åˆ¶çš„
        result_image_bgr = cv2.cvtColor(np.asarray(result_image), cv2.COLOR_RGB2BGR)
        if self.enable_vis:
            cv2.imshow("YOLO Detection", result_image_bgr)
            cv2.waitKey(1)

def main(args=None):
    rclpy.init(args=args)
    detector = RosYOLODetector()
    detector.get_logger().info("ROS YOLO detector with Detection2DArray output started.")
    rclpy.spin(detector)
    detector.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()